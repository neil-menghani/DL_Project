{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from model import model\n",
    "from torch.utils.data import DataLoader\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'data'\n",
    "annotation_csv = 'data/annotation.csv'\n",
    "save_dir = 'save'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((512,512)),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "batch_size =3\n",
    "\n",
    "#Evaluation Dataset is [eval_num,134] of labeled data:\n",
    "eval_num = 120\n",
    "eval_scene_index = np.arange(eval_num,134)\n",
    "eval_set = LabeledDataset(\n",
    "        image_folder = image_folder,\n",
    "        annotation_file = annotation_csv,\n",
    "        scene_index = eval_scene_index,\n",
    "        transform = transform,\n",
    "        extra_info = True\n",
    "    )\n",
    "eval_loader = DataLoader(eval_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True,\n",
    "                               collate_fn=collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(pred, target):\n",
    "    pred = torch.squeeze(pred)\n",
    "    target = torch.squeeze(target)\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    output = loss(pred, target.float())\n",
    "    return output\n",
    "\n",
    "def avg_loss(encoder, decoder, loader, device):\n",
    "    total_loss = 0\n",
    "    for i in range(len(loader)):\n",
    "        try:\n",
    "            samples, target, road_image, _ = loader.__next__()\n",
    "        except:\n",
    "            loader = iter(loader)\n",
    "            samples, target, road_image, extra = loader.__next__()\n",
    "        samples = torch.stack(samples).view(batch_size, 18, 512, 512).to(device)\n",
    "        road_image = torch.stack(road_image).view(batch_size, 1, 800, 800).float().to(device)\n",
    "        \n",
    "        #Generator output:\n",
    "        test_pred = decoder(encoder(samples))\n",
    "        total_loss += compute_losses(test_pred, road_image)\n",
    "        \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples,target,road_image,extra = iter(eval_loader).next()\n",
    "samples = torch.stack(samples).view(batch_size, 18, 512, 512).to(device)\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path used in train.py;\n",
    "model_path = {'encoder': 'save/encoder_save', 'decoder': 'save/decoder_save'}\n",
    "#Rebuild models from param:\n",
    "encoder = model.Encoder(18,800,800,False,num_imgs=6).to(device)\n",
    "encoder.load_state_dict(torch.load(model_path['encoder'])) #Error Here\n",
    "decoder = model.Decoder(encoder.resnet_encoder.num_ch_enc).to(device)\n",
    "decoder.load_state_dict(torch.load(model_path['decoder'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if __name__ == '__main__':\n",
    "        #Path used in train.py;\n",
    "        model_path = {'encoder': 'save/encoder_save', 'decoder': 'save/decoder_save'}\n",
    "        #Rebuild models from param:\n",
    "        encoder = model.Encoder(18,800,800,False,num_imgs=6).to(device)\n",
    "        encoder.load_state_dict(torch.load(model_path['encoder']))\n",
    "        decoder = model.Decoder(encoder.resnet_encoder.num_ch_enc).to(device)\n",
    "        decoder.load_state_dict(torch.load(model_path['decoder']))\n",
    "        \n",
    "        print(\"Avg Evaluation Loss is:\")\n",
    "        print(avg_loss(encoder,decoder,eval_loader,device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
